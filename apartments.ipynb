{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2c2acf4-5f01-46a0-ab94-7a6e4cad1eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import lxml\n",
    "import numbers\n",
    "from collections import defaultdict\n",
    "from uszipcode import *\n",
    "\n",
    "import sys\n",
    "sys.path.insert(2, './apartments-scraper-master/')\n",
    "\n",
    "from parse_apartments import *\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "def load_big_city(change_rate=0.05):\n",
    "    df = pd.read_csv('./census_data/us_census_data_2022.csv')\n",
    "    df = df[df['growth']>=change_rate]\n",
    "    df = df.groupby(\"usps\").filter(lambda x: len(x) >= 3)\n",
    "    \n",
    "    print(df['usps'].value_counts())\n",
    "    return df\n",
    "    \n",
    "def get_all_city(population_limit=10000, density_limit=500, county='King County', major_city='Seattle'):\n",
    "    engine = SearchEngine()\n",
    "    allzips = {}\n",
    "    for i in range(100000): \n",
    "        zipcode = str(i).zfill(5)\n",
    "        try: allzips[zipcode] = engine.by_zipcode(zipcode).to_dict()\n",
    "        except: pass\n",
    "\n",
    "    allzips = pd.DataFrame(allzips).T.reset_index(drop = True)\n",
    "    def city_apartment_url(x):\n",
    "        url = 'https://www.apartments.com/' + x.major_city.lower() + '-' + x.state.lower()\n",
    "        return url\n",
    "\n",
    "    def city_zillow_url(x):\n",
    "        url = 'http://www.zillow.com/homes/for_sale/' + x.major_city.lower() \n",
    "        return url\n",
    "\n",
    "    allzips['apartment_URL'] = allzips.apply(city_apartment_url, axis=1)\n",
    "    allzips['zillow_URL'] = allzips.apply(city_zillow_url, axis=1)\n",
    "    allzips['search_key'] = allzips['major_city'].replace(' ','').str.lower()  + '-' + allzips['state'].str.lower() + '-' + allzips.zipcode\n",
    "    \n",
    "    allzips = allzips[(allzips['population']>=population_limit) & (allzips['population_density']>=density_limit)]\n",
    "    \n",
    "    big_city = load_big_city()\n",
    "    # allzips = allzips[~allzips['major_city'].isin(big_city['usps'])]\n",
    "\n",
    "    if county is not None:\n",
    "        allzips = allzips[(allzips['county']==county)]\n",
    "    elif major_city is not None: \n",
    "        allzips = allzips[(allzips['major_city']==major_city)]\n",
    "    else: \n",
    "        allzips = allzips\n",
    "    \n",
    "    print(\"Number of city:{}\".format(str(allzips.shape[0])))\n",
    "    return allzips\n",
    "\n",
    "\n",
    "def get_apt_url(search_key):\n",
    "    # search_key = 'chicago-il-60615'\n",
    "    url = 'https://www.apartments.com/' + search_key\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'}\n",
    "    \n",
    "    page = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    soup.prettify()\n",
    "\n",
    "    supply = soup.find('h3', {\"class\": \"count\"})\n",
    "    supply_str = supply.text.strip()\n",
    "    total_num_pages = soup.find('p', {\"class\": \"searchResults\"})\n",
    "    num_string = total_num_pages.text.strip() if total_num_pages is not None else '1'\n",
    "    num_page = int(num_string.split()[-1])\n",
    "    print(\"Number of page:{}\".format(str(num_page)))\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for i in range(1,num_page+1):\n",
    "        url_with_page = url + '/' + str(i) + '/'\n",
    "        print(url_with_page)\n",
    "        page = requests.get(url_with_page, headers=headers)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        soup.prettify()\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        link = [x.article['data-url'] for x in soup.findAll('li',{'class':'mortar-wrapper'})]\n",
    "        address = [x.article['data-streetaddress'] for x in soup.findAll('li',{'class':'mortar-wrapper'})]\n",
    "        df['link'] = link\n",
    "        df['address'] = address\n",
    "        df['supply'] = supply_str\n",
    "        print(\"Number of listing:{}\".format(str(df.shape[0])))\n",
    "\n",
    "        data.append(df)\n",
    "\n",
    "    data = pd.concat(data)\n",
    "    data['search_key'] = search_key\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_apt_price_detail(url):\n",
    "    # https://www.apartments.com/regents-park-chicago-il/5sl3n3q/\n",
    "    print(url)\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'}\n",
    "\n",
    "    page = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    soup.prettify()\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    name = [x.text.strip() for x in soup.findAll('h1',{'class':'propertyName'})]\n",
    "    zipcode = [x.text.strip() for x in soup.findAll('span',{'class':'stateZipContainer'})]\n",
    "    neighborhood = [x.text.strip() for x in soup.findAll('a',{'class':'neighborhood'})]\n",
    "    price_detail = [x.text for x in soup.findAll('span',{'class':'rentLabel'})]\n",
    "    model_detail = [x.text for x in soup.findAll('span',{'class':'detailsTextWrapper'})]\n",
    "\n",
    "    model_detail = list(map(lambda a: a.strip(), model_detail))\n",
    "    model_detail = model_detail[::2]\n",
    "\n",
    "    element = str([x.text.strip() for x in soup.findAll('div',{'class':'column'})])\n",
    "    home_type = str([x.text.strip() for x in soup.findAll('script',{'type':'text/javascript'})])\n",
    "\n",
    "    df['price_detail'] = price_detail\n",
    "    df['model_detail'] = model_detail\n",
    "\n",
    "    df['min_price'] = df['price_detail'].str.split('–').str[0]\n",
    "    df['max_price'] = df['price_detail'].str.split('–').str[1]\n",
    "\n",
    "    df['price_detail'] = df['price_detail'].astype('str')\n",
    "    df['model_detail'] = df['model_detail'].astype('str')\n",
    "\n",
    "    df.replace('\\r\\n','', regex=True, inplace=True)\n",
    "    df['model'] = df['model_detail'].str.split(',').str[0]\n",
    "    df['model'] = df['model'].astype('str')\n",
    "    df['bath'] = df['model_detail'].str.split(',').str[1]\n",
    "    df['bath'] = df['bath'].astype('str')\n",
    "    df['sqft'] = df['model_detail'].str.split(' ').str[-3]\n",
    "    df['sqft'] = pd.to_numeric(df['sqft'].str.replace('[^-.0-9]','',regex=True))\n",
    "    df['url'] = url\n",
    "    df['property_name'] = str(*name)\n",
    "    df['state'] = str(*zipcode).split('\\n')[0]\n",
    "    df['zipcode'] = str(*zipcode).split('\\n')[1]\n",
    "    df['neighborhood'] = str(*neighborhood)\n",
    "\n",
    "    year = element[element.find('Built in')+9:element.find('Built in')+13]\n",
    "    df['year'] = int(year) if year[0].isdigit() else np.NaN\n",
    "    home_type = home_type[home_type.find('propertyType')+16:home_type.find('listingNeighborhood')-19]\n",
    "    df['home_type'] = str(home_type) if type(home_type) == str else np.NaN\n",
    "    df['home_type'] = df['home_type'].str.split(\"\\'\").str[0]\n",
    "\n",
    "    df['min_price'] = pd.to_numeric(df['min_price'].str.replace('[^-.0-9]','',regex=True)) if df['min_price'].dtype == 'object' else np.NaN\n",
    "    df['max_price'] = pd.to_numeric(df['max_price'].str.replace('[^-.0-9]','',regex=True)) if df['min_price'].dtype == 'object' else np.NaN\n",
    "    df['avg_price'] = (df['min_price'] + df['max_price'])/2 if df['max_price'].notnull().values.any() else df['min_price']\n",
    "\n",
    "    return df[['state','zipcode','neighborhood','property_name','year','home_type','model','avg_price','min_price','max_price','bath','sqft','url','model_detail']]\n",
    "\n",
    "\n",
    "def get_apt_nearby_detail(url):\n",
    "    # url = https://www.apartments.com/regents-park-chicago-il/5sl3n3q/\n",
    "    print(url)\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'}\n",
    "    \n",
    "    page = requests.get(url, headers=headers)\n",
    "    first_df = pd.read_html(page.text)[0]\n",
    "    a = 1 if len(first_df.columns) == 2 else 2\n",
    "\n",
    "    df_edu = pd.read_html(page.text)[a]\n",
    "    df_edu.columns = ['name', 'method', 'time', 'Distance']\n",
    "    df_edu['type'] = 'edu'\n",
    "\n",
    "    df_subway = pd.read_html(page.text)[a+1]\n",
    "    df_subway.columns = ['name', 'method', 'time', 'Distance']\n",
    "    df_subway['type'] = 'subway'\n",
    "\n",
    "    df_rail = pd.read_html(page.text)[a+2]\n",
    "    df_rail.columns = ['name', 'method', 'time', 'Distance']\n",
    "    df_rail['type'] = 'rail'\n",
    "\n",
    "    df_airport = pd.read_html(page.text)[a+3]\n",
    "    df_airport.columns = ['name', 'method', 'time', 'Distance']\n",
    "    df_airport['type'] = 'airport'\n",
    "\n",
    "    df_shopping = pd.read_html(page.text)[a+4]\n",
    "    df_shopping.columns = ['name', 'method', 'time', 'Distance']\n",
    "    df_shopping['type'] = 'shopping'\n",
    "\n",
    "    df_park = pd.read_html(page.text)[a+5]\n",
    "    df_park.columns = ['name', 'method', 'time', 'Distance']\n",
    "    df_park['type'] = 'park'\n",
    "\n",
    "    df_military = pd.read_html(page.text)[a+6]\n",
    "    df_military.columns = ['name', 'method', 'time', 'Distance']\n",
    "    df_military['type'] = 'military'\n",
    "\n",
    "    frames = [df_edu,df_subway,df_rail,df_airport,df_shopping,df_park,df_military]\n",
    "    data = pd.concat(frames)\n",
    "    data['url'] = url\n",
    "    data.replace(':','', regex=True, inplace=True)    \n",
    "    \n",
    "    return data[['url','type','name', 'method', 'time', 'Distance']]\n",
    "\n",
    "\n",
    "def wrap_apt(search_key):\n",
    "    #search_key = 'chicago-il-60651'\n",
    "    final = []\n",
    "    df = get_apt_url(search_key) \n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        url = row['link']\n",
    "        df = get_apt_price_detail(url)\n",
    "        df['address'] = row['address']\n",
    "        df['search_key'] = row['search_key']\n",
    "        df['supply'] = row['supply']\n",
    "        final.append(df)\n",
    "\n",
    "    final = pd.concat(final)\n",
    "    return final[['search_key','supply','state','zipcode','neighborhood','address','property_name','year','home_type','model','avg_price','min_price','max_price','bath','sqft','url','model_detail']].drop_duplicates()\n",
    "\n",
    "def get_apt_data(population_limit=10000, density_limit=500, county='King County', major_city='Seattle'):\n",
    "    final = []\n",
    "    us_data = get_all_city(population_limit=population_limit, density_limit=density_limit, county=county, major_city=major_city)\n",
    "    for index, row in us_data.iterrows():\n",
    "        print(row['search_key'])\n",
    "        try: df = wrap_apt(row['search_key'])\n",
    "        except: pass\n",
    "        df['major_city'] = row['major_city']\n",
    "        df['county'] = row['county']\n",
    "        df['timezone'] = row['timezone']\n",
    "        df['radius_in_miles'] = row['radius_in_miles']\n",
    "        df['population'] = row['population']\n",
    "        df['population_density'] = row['population_density']\n",
    "        df['land_area_in_sqmi'] = row['land_area_in_sqmi']\n",
    "        df['water_area_in_sqmi'] = row['water_area_in_sqmi']\n",
    "        df['housing_units'] = row['housing_units']\n",
    "        df['occupied_housing_units'] = row['occupied_housing_units']\n",
    "        df['median_home_value'] = row['median_home_value']\n",
    "        df['median_household_income'] = row['median_household_income']\n",
    "\n",
    "        final.append(df)\n",
    "\n",
    "    final = pd.concat(final)\n",
    "    final=final.replace('ApartmentUnitForRent','Apartment')\n",
    "    \n",
    "    return final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
